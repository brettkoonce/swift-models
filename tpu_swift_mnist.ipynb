{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpu-swift-mnist",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Swift",
      "name": "swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brettkoonce/swift-models/blob/master/tpu_swift_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vipArwIRZk6R",
        "colab_type": "text"
      },
      "source": [
        "# Install Swift for Tensorflow in a shell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76f869f8-ea8d-43fb-ee9b-c43490ab75f9"
      },
      "source": [
        "%install '.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"master\"))' Datasets ImageClassificationModels\n",
        "print(\"\\u{001B}[2J\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXEcph33ZfTy",
        "colab_type": "text"
      },
      "source": [
        "# XLA device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTIwdknHZjoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4d709da6-1eb4-4594-cca2-095911bc4baf"
      },
      "source": [
        "let device = Device.defaultXLA\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "â–¿ Device(kind: .GPU, ordinal: 0, backend: .XLA)\n",
              "  - kind : TensorFlow.Device.Kind.GPU\n",
              "  - ordinal : 0\n",
              "  - backend : TensorFlow.Device.Backend.XLA\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzOUslBHYsCR",
        "colab_type": "text"
      },
      "source": [
        "# MNIST-XLA-TPU\n",
        "\n",
        "Next, we will tackle MNIST on a TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaQOyz6TRavs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8086d0a0-e0f3-424c-dd1d-b96c96d5d0c0"
      },
      "source": [
        "import Datasets\n",
        "import TensorFlow\n",
        "\n",
        "struct CNN: Layer {\n",
        "  var conv1a = Conv2D<Float>(filterShape: (3, 3, 1, 32), padding: .same, activation: relu)\n",
        "  var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 32), padding: .same, activation: relu)\n",
        "  var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "\n",
        "  var flatten = Flatten<Float>()\n",
        "  var inputLayer = Dense<Float>(inputSize: 14 * 14 * 32, outputSize: 512, activation: relu)\n",
        "  var hiddenLayer = Dense<Float>(inputSize: 512, outputSize: 512, activation: relu)\n",
        "  var outputLayer = Dense<Float>(inputSize: 512, outputSize: 10)\n",
        "  \n",
        "  @differentiable\n",
        "  public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "    let convolutionLayer = input.sequenced(through: conv1a, conv1b, pool1)\n",
        "    return convolutionLayer.sequenced(through: flatten, inputLayer, hiddenLayer, outputLayer)\n",
        "  }  \n",
        "}\n",
        "\n",
        "let batchSize = 128\n",
        "let epochCount = 12\n",
        "var model = CNN()\n",
        "var optimizer = SGD(for: model, learningRate: 0.1)\n",
        "let dataset = MNIST(batchSize: batchSize)\n",
        "\n",
        "let device = Device.defaultXLA\n",
        "model.move(to: device)\n",
        "optimizer = SGD(copying: optimizer, to: device)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for (epoch, epochBatches) in dataset.training.prefix(epochCount).enumerated() {\n",
        "    Context.local.learningPhase = .training\n",
        "    var trainingLossSum: Float = 0\n",
        "    var trainingBatchCount = 0\n",
        "    for batch in epochBatches {\n",
        "        let (images, labels) = (batch.data, batch.label)\n",
        "        let deviceImages = Tensor(copying: images, to: device)\n",
        "        let deviceLabels = Tensor(copying: labels, to: device)\n",
        "        let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "            let logits = model(deviceImages)\n",
        "            return softmaxCrossEntropy(logits: logits, labels: deviceLabels)\n",
        "        }\n",
        "        trainingLossSum += loss.scalarized()\n",
        "        trainingBatchCount += 1\n",
        "        optimizer.update(&model, along: gradients)\n",
        "\t    LazyTensorBarrier()\n",
        "    }\n",
        "\n",
        "    Context.local.learningPhase = .inference\n",
        "    var testLossSum: Float = 0\n",
        "    var testBatchCount = 0\n",
        "    var correctGuessCount = 0\n",
        "    var totalGuessCount = 0\n",
        "    for batch in dataset.validation {\n",
        "        let (images, labels) = (batch.data, batch.label)\n",
        "        let deviceImages = Tensor(copying: images, to: device)\n",
        "        let deviceLabels = Tensor(copying: labels, to: device)\n",
        "        let logits = model(deviceImages)\n",
        "        testLossSum += softmaxCrossEntropy(logits: logits, labels: deviceLabels).scalarized()\n",
        "        testBatchCount += 1\n",
        "\n",
        "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== deviceLabels\n",
        "        correctGuessCount = correctGuessCount\n",
        "            + Int(\n",
        "                Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "        totalGuessCount = totalGuessCount + batch.data.shape[0]\n",
        "\t    LazyTensorBarrier()\n",
        "    }\n",
        "\n",
        "    let accuracy = Float(correctGuessCount) / Float(totalGuessCount)\n",
        "    print(\n",
        "        \"\"\"\n",
        "        [Epoch \\(epoch + 1)] \\\n",
        "        Accuracy: \\(correctGuessCount)/\\(totalGuessCount) (\\(accuracy)) \\\n",
        "        Loss: \\(testLossSum / Float(testBatchCount))\n",
        "        \"\"\"\n",
        "    )\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading resource: train-images-idx3-ubyte\n",
            "Loading resource: train-labels-idx1-ubyte\n",
            "Loading resource: t10k-images-idx3-ubyte\n",
            "Loading resource: t10k-labels-idx1-ubyte\n",
            "Starting training...\n",
            "[Epoch 1] Accuracy: 9630/10000 (0.963) Loss: 0.113842346\n",
            "[Epoch 2] Accuracy: 9714/10000 (0.9714) Loss: 0.089315146\n",
            "[Epoch 3] Accuracy: 9817/10000 (0.9817) Loss: 0.05626795\n",
            "[Epoch 4] Accuracy: 9845/10000 (0.9845) Loss: 0.04341101\n",
            "[Epoch 5] Accuracy: 9851/10000 (0.9851) Loss: 0.0448411\n",
            "[Epoch 6] Accuracy: 9849/10000 (0.9849) Loss: 0.0460658\n",
            "[Epoch 7] Accuracy: 9881/10000 (0.9881) Loss: 0.038156476\n",
            "[Epoch 8] Accuracy: 9868/10000 (0.9868) Loss: 0.03822924\n",
            "[Epoch 9] Accuracy: 9884/10000 (0.9884) Loss: 0.039507892\n",
            "[Epoch 10] Accuracy: 9876/10000 (0.9876) Loss: 0.039613236\n",
            "[Epoch 11] Accuracy: 9882/10000 (0.9882) Loss: 0.038583163\n",
            "[Epoch 12] Accuracy: 9888/10000 (0.9888) Loss: 0.043279253\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}